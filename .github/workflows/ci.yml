name: ci

on:
  pull_request:
    paths-ignore: ['.codex/**']
  push:
    branches: [main]
    paths-ignore: ['.codex/**']
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  issues: write

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          cache: 'npm'
          cache-dependency-path: |
            web/package-lock.json
            webapp/package-lock.json

      - name: Install Python dev deps
        shell: bash
        run: |
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Python unit tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m "not integration" 2>&1 | tee unit-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend web tests
        shell: bash
        run: |
          if [ -f web/package.json ]; then
            cd web
            set -o pipefail
            npm ci
            npm test 2>&1 | tee ../web-vitest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend webapp build
        shell: bash
        run: |
          if [ -f webapp/package.json ]; then
            cd webapp
            set -o pipefail
            npm ci
            npm run build 2>&1 | tee ../webapp-build.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Pick tail and write summary
        id: picktail_unit
        if: always()
        shell: bash
        run: |
          PATTERN='Traceback|ERROR|CRITICAL|Exception|AssertionError|TypeError|ReferenceError|TS[0-9]+:|not found|exit code [1-9]'
          candidates=()
          [ -s unit-pytest.log ] && candidates+=("unit-pytest.log")
          [ -s web-vitest.log ] && candidates+=("web-vitest.log")
          [ -s webapp-build.log ] && candidates+=("webapp-build.log")
          pick=""
          for f in "${candidates[@]}"; do
            if grep -Eq "$PATTERN" "$f"; then pick="$f"; break; fi
          done
          if [ -z "$pick" ] && [ ${#candidates[@]} -gt 0 ]; then
            pick="$(ls -t "${candidates[@]}" | head -n1)"
          fi
          if [ -z "$pick" ]; then
            echo "no logs" > none.txt
            pick=none.txt
          fi
          echo "tail_path=$pick" >> $GITHUB_OUTPUT
          {
            echo "## Summary"
            echo
            echo "```"
            tail -n 200 "$pick"
            echo "```"
          } >> $GITHUB_STEP_SUMMARY

      - name: Extract AI hints (unit)
        if: always()
        shell: bash
        run: |
          : > ai-hints-unit.txt
          ts="$(date +%H:%M:%S)"
          for f in unit-pytest.log web-vitest.log webapp-build.log; do
            [ -f "$f" ] || continue
            grep -E '(Traceback|ERROR|CRITICAL|Exception|AssertionError|TypeError|ReferenceError|TS[0-9]+:|not found|exit code [1-9])' "$f" | sed "s/^/$ts /" >> ai-hints-unit.txt || true
          done
          if [ ! -s ai-hints-unit.txt ]; then echo 'no obvious errors found' > ai-hints-unit.txt; fi
          {
            echo '## AI hints (unit)'
            echo
            echo '```'
            tail -n 40 ai-hints-unit.txt
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts (unit)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-unit
          path: |
            unit-pytest.log
            web-vitest.log
            webapp-build.log
            ai-hints-unit.txt
            none.txt
          if-no-files-found: ignore

      - name: Upsert failure comment (unit)
        if: failure() && github.event_name == 'pull_request'
        continue-on-error: true
        env:
          TAIL_PATH: ${{ steps.picktail_unit.outputs.tail_path }}
          TITLE: "CI / unit"
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const marker = '<!-- CI_FAILURE_SUMMARY -->';
            let tail = 'no logs';
            let hints = 'no logs';
            try { tail = fs.readFileSync(process.env.TAIL_PATH, 'utf8'); } catch (e) {}
            try { hints = fs.readFileSync('ai-hints-unit.txt', 'utf8'); } catch (e) {}
            const tail_snippet = tail.split('\n').slice(-200).join('\n');
            const hints_snippet = hints.split('\n').slice(-40).join('\n');
            const body = [
              marker,
              process.env.TITLE,
              '',
              '```',
              tail_snippet || 'no logs',
              '```',
              '',
              '## AI hints',
              '',
              '```',
              hints_snippet || 'no logs',
              '```',
              '',
              'Reply with `@codex review` to request an AI patch.'
            ].join('\n');
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body && c.body.includes(marker));
            if (existing) {
              await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body});
            } else {
              await github.rest.issues.createComment({owner, repo, issue_number, body});
            }

      - name: Delete failure comment on success (unit)
        if: success() && github.event_name == 'pull_request'
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const marker = '<!-- CI_FAILURE_SUMMARY -->';
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body && c.body.includes(marker));
            if (existing) {
              await github.rest.issues.deleteComment({owner, repo, comment_id: existing.id});
            }
  integration:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: unit
    steps:
      - uses: actions/checkout@v4

      - name: Prepare .env.ci
        shell: bash
        run: |
          printf "PG_HOST=postgres\nPG_PORT=5432\nPG_USER=%s\nPG_PASSWORD=%s\nPG_DATABASE=%s\nPOSTGRES_HOST=postgres\nPOSTGRES_PORT=5432\nPOSTGRES_USER=%s\nPOSTGRES_PASSWORD=%s\nPOSTGRES_DB=%s\nDATABASE_URL=postgresql://%s:%s@postgres:5432/%s\n" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" > .env.ci

      - name: Build images
        shell: bash
        run: |
          export COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci build --pull 2>&1 | tee compose-build.txt
          exit ${PIPESTATUS[0]}

      - name: Up services
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci up -d --wait 2>&1 | tee compose-up.txt
          exit ${PIPESTATUS[0]}

      - name: Dump compose logs
        if: always()
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          docker compose $COMPOSE_FILES --env-file .env.ci ps > compose-ps.txt || true
          docker compose $COMPOSE_FILES --env-file .env.ci logs --no-color > compose-logs.txt || true

      - name: Python integration tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m integration 2>&1 | tee integration-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Pick tail and write summary
        id: picktail_integration
        if: always()
        shell: bash
        run: |
          PATTERN='Traceback|ERROR|CRITICAL|Exception|ValueError|not enough values to unpack|connection refused|pg_isready|curl:|panic|segmentation|Address already in use'
          candidates=()
          [ -s compose-logs.txt ] && candidates+=("compose-logs.txt")
          [ -s integration-pytest.log ] && candidates+=("integration-pytest.log")
          [ -s compose-up.txt ] && candidates+=("compose-up.txt")
          [ -s compose-build.txt ] && candidates+=("compose-build.txt")
          pick=""
          for f in "${candidates[@]}"; do
            if grep -Eq "$PATTERN" "$f"; then pick="$f"; break; fi
          done
          if [ -z "$pick" ] && [ ${#candidates[@]} -gt 0 ]; then
            pick="$(ls -t "${candidates[@]}" | head -n1)"
          fi
          if [ -z "$pick" ]; then
            echo "no logs" > none.txt
            pick=none.txt
          fi
          echo "tail_path=$pick" >> $GITHUB_OUTPUT
          {
            echo "## Summary"
            echo
            echo "```"
            tail -n 200 "$pick"
            echo "```"
          } >> $GITHUB_STEP_SUMMARY

      - name: Extract AI hints (integration)
        if: always()
        shell: bash
        run: |
          : > ai-hints-integration.txt
          ts="$(date +%H:%M:%S)"
          for f in compose-logs.txt integration-pytest.log compose-up.txt compose-build.txt; do
            [ -f "$f" ] || continue
            grep -E '(Traceback|ERROR|CRITICAL|Exception|ValueError|not enough values to unpack|connection refused|pg_isready|curl:|panic|segmentation|Address already in use)' "$f" | sed "s/^/$ts /" >> ai-hints-integration.txt || true
          done
          if [ ! -s ai-hints-integration.txt ]; then echo 'no obvious errors found' > ai-hints-integration.txt; fi
          {
            echo '## AI hints (integration)'
            echo
            echo '```'
            tail -n 40 ai-hints-integration.txt
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts (integration)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-integration
          path: |
            compose-ps.txt
            compose-logs.txt
            compose-up.txt
            compose-build.txt
            integration-pytest.log
            ai-hints-integration.txt
            none.txt
          if-no-files-found: ignore

      - name: Upsert failure comment (integration)
        if: failure() && github.event_name == 'pull_request'
        continue-on-error: true
        env:
          TAIL_PATH: ${{ steps.picktail_integration.outputs.tail_path }}
          TITLE: "CI / integration"
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const marker = '<!-- CI_FAILURE_SUMMARY -->';
            let tail = 'no logs';
            let hints = 'no logs';
            try { tail = fs.readFileSync(process.env.TAIL_PATH, 'utf8'); } catch (e) {}
            try { hints = fs.readFileSync('ai-hints-integration.txt', 'utf8'); } catch (e) {}
            const tail_snippet = tail.split('\n').slice(-200).join('\n');
            const hints_snippet = hints.split('\n').slice(-40).join('\n');
            const body = [
              marker,
              process.env.TITLE,
              '',
              '```',
              tail_snippet || 'no logs',
              '```',
              '',
              '## AI hints',
              '',
              '```',
              hints_snippet || 'no logs',
              '```',
              '',
              'Reply with `@codex review` to request an AI patch.'
            ].join('\n');
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body && c.body.includes(marker));
            if (existing) {
              await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body});
            } else {
              await github.rest.issues.createComment({owner, repo, issue_number, body});
            }

      - name: Delete failure comment on success (integration)
        if: success() && github.event_name == 'pull_request'
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const marker = '<!-- CI_FAILURE_SUMMARY -->';
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body && c.body.includes(marker));
            if (existing) {
              await github.rest.issues.deleteComment({owner, repo, comment_id: existing.id});
            }
  publish_logs:
    needs: [unit, integration]
    if: ${{ always() && github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository }}
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}

      - name: Download all CI logs artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: ci-logs-*
          merge-multiple: true

      - name: Sanitize logs into .codex/last-run
        shell: bash
        run: |
          rm -rf .codex/last-run
          mkdir -p .codex/last-run
          python - <<'PY'
          import os,re,glob,io,sys,shutil,json
          out_dir = ".codex/last-run"
          os.makedirs(out_dir, exist_ok=True)
          files = sorted(glob.glob("*.log")+glob.glob("*.txt"))
          # Redaction rules
          rules = [
            (re.compile(r'(?i)\b(PG_PASSWORD|POSTGRES_PASSWORD|REDIS_PASSWORD|MINIO_SECRET_KEY|AWS_SECRET_ACCESS_KEY|OPENAI_API_KEY|API_KEY|SECRET|TOKEN|PASSWORD)\s*=\s*[^\s]+'), r'\1=<redacted>'),
            (re.compile(r'(?i)\bDATABASE_URL\s*=\s*\S+'), 'DATABASE_URL=<redacted>'),
            (re.compile(r'postgres(?:ql|\+psycopg)?://([^:@/]+):([^@/]+)@'), r'postgresql://\1:<redacted>@'),
            (re.compile(r'://([^:@/]+):([^@/]+)@'), r'://\1:<redacted>@'),
            (re.compile(r'Bearer\s+[A-Za-z0-9\-._~+/]+=*'), 'Bearer <redacted>'),
            (re.compile(r'(?i)(Authorization:\s*)\S+'), r'\1<redacted>')
          ]
          for src in files:
            try:
              data = open(src,'r',errors='ignore').read()
            except Exception:
              continue
            red = data
            for pat, sub in rules:
              red = pat.sub(sub, red)
            with open(os.path.join(out_dir, os.path.basename(src)), 'w', encoding='utf-8') as f:
              f.write(red)
          meta = {
            "run_id": os.getenv("GITHUB_RUN_ID"),
            "run_attempt": os.getenv("GITHUB_RUN_ATTEMPT"),
            "sha": os.getenv("GITHUB_SHA"),
            "ref": os.getenv("GITHUB_REF")
          }
          with open(os.path.join(out_dir, "meta.json"), "w") as jf:
            json.dump(meta, jf, indent=2)
          PY

      - name: Secret quick scan (sanitized copies)
        id: leakscan
        shell: bash
        run: |
          set +e
          hits_file=".codex/last-run/_secret_hits.txt"
          # Grep a compact set of high-signal patterns
          egrep -RIn "(?i)(password=|postgres_password=|secret=|api[_-]?key=|authorization:|Bearer\s+[A-Za-z0-9\-._~+/]+=*)" .codex/last-run > "$hits_file" || true
          if [ -s "$hits_file" ]; then
            echo "found=1" >> $GITHUB_OUTPUT
            echo "Secrets-like patterns still present after redaction:"
            tail -n 50 "$hits_file"
          else
            rm -f "$hits_file"
            echo "found=0" >> $GITHUB_OUTPUT
          fi

      - name: Commit last-run logs into PR branch (no CI loop)
        if: steps.leakscan.outputs.found == '0'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "[ci-logs] update last-run (sanitized, no-ci)"
          file_pattern: ".codex/last-run/**"
          add_options: "--all"
