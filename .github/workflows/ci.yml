name: ci

on:
  pull_request:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  issues: write

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          cache: 'npm'
          cache-dependency-path: |
            web/package-lock.json
            webapp/package-lock.json

      - name: Install Python dev deps
        shell: bash
        run: |
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Python unit tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m "not integration" 2>&1 | tee unit-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend web tests
        shell: bash
        run: |
          if [ -f web/package.json ]; then
            cd web
            set -o pipefail
            npm ci
            npm test 2>&1 | tee ../web-vitest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend webapp build
        shell: bash
        run: |
          if [ -f webapp/package.json ]; then
            cd webapp
            set -o pipefail
            npm ci
            npm run build 2>&1 | tee ../webapp-build.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Pick tail and write summary
        id: picktail_unit
        if: always()
        shell: bash
        run: |
          PATTERN='Traceback|ERROR|CRITICAL|Exception|AssertionError|TypeError|ReferenceError|TS[0-9]+:|not found|exit code [1-9]'
          candidates=()
          [ -s unit-pytest.log ] && candidates+=("unit-pytest.log")
          [ -s web-vitest.log ] && candidates+=("web-vitest.log")
          [ -s webapp-build.log ] && candidates+=("webapp-build.log")
          pick=""
          for f in "${candidates[@]}"; do
            if grep -Eq "$PATTERN" "$f"; then pick="$f"; break; fi
          done
          if [ -z "$pick" ] && [ ${#candidates[@]} -gt 0 ]; then
            pick="$(ls -t "${candidates[@]}" | head -n1)"
          fi
          if [ -z "$pick" ]; then
            echo "no logs" > none.txt
            pick=none.txt
          fi
          echo "tail_path=$pick" >> $GITHUB_OUTPUT
          {
            echo "## Summary"
            echo
            echo "```"
            tail -n 200 "$pick"
            echo "```"
          } >> $GITHUB_STEP_SUMMARY

      - name: Extract AI hints (unit)
        if: always()
        shell: bash
        run: |
          : > ai-hints-unit.txt
          ts="$(date +%H:%M:%S)"
          for f in unit-pytest.log web-vitest.log webapp-build.log; do
            [ -f "$f" ] || continue
            grep -E '(Traceback|ERROR|CRITICAL|Exception|AssertionError|TypeError|ReferenceError|TS[0-9]+:|not found|exit code [1-9])' "$f" | sed "s/^/$ts /" >> ai-hints-unit.txt || true
          done
          if [ ! -s ai-hints-unit.txt ]; then echo 'no obvious errors found' > ai-hints-unit.txt; fi
          {
            echo '## AI hints (unit)'
            echo
            echo '```'
            tail -n 40 ai-hints-unit.txt
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts (unit)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-unit
          path: |
            unit-pytest.log
            web-vitest.log
            webapp-build.log
            ai-hints-unit.txt
            none.txt
          if-no-files-found: ignore
  integration:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: unit
    steps:
      - uses: actions/checkout@v5

      - name: Prepare .env.ci
        shell: bash
        run: |
          printf "PG_HOST=postgres\nPG_PORT=5432\nPG_USER=%s\nPG_PASSWORD=%s\nPG_DATABASE=%s\nPOSTGRES_HOST=postgres\nPOSTGRES_PORT=5432\nPOSTGRES_USER=%s\nPOSTGRES_PASSWORD=%s\nPOSTGRES_DB=%s\nDATABASE_URL=postgresql://%s:%s@postgres:5432/%s\n" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" > .env.ci

      - name: Build images
        shell: bash
        run: |
          export COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci build --pull 2>&1 | tee compose-build.txt
          exit ${PIPESTATUS[0]}

      - name: Up services
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci up -d --wait 2>&1 | tee compose-up.txt
          exit ${PIPESTATUS[0]}

      - name: Dump compose logs
        if: always()
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          docker compose $COMPOSE_FILES --env-file .env.ci ps > compose-ps.txt || true
          docker compose $COMPOSE_FILES --env-file .env.ci logs --no-color > compose-logs.txt || true

      - name: Python integration tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m integration 2>&1 | tee integration-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Pick tail and write summary
        id: picktail_integration
        if: always()
        shell: bash
        run: |
          PATTERN='Traceback|ERROR|CRITICAL|Exception|ValueError|not enough values to unpack|connection refused|pg_isready|curl:|panic|segmentation|Address already in use'
          candidates=()
          [ -s compose-logs.txt ] && candidates+=("compose-logs.txt")
          [ -s integration-pytest.log ] && candidates+=("integration-pytest.log")
          [ -s compose-up.txt ] && candidates+=("compose-up.txt")
          [ -s compose-build.txt ] && candidates+=("compose-build.txt")
          pick=""
          for f in "${candidates[@]}"; do
            if grep -Eq "$PATTERN" "$f"; then pick="$f"; break; fi
          done
          if [ -z "$pick" ] && [ ${#candidates[@]} -gt 0 ]; then
            pick="$(ls -t "${candidates[@]}" | head -n1)"
          fi
          if [ -z "$pick" ]; then
            echo "no logs" > none.txt
            pick=none.txt
          fi
          echo "tail_path=$pick" >> $GITHUB_OUTPUT
          {
            echo "## Summary"
            echo
            echo "```"
            tail -n 200 "$pick"
            echo "```"
          } >> $GITHUB_STEP_SUMMARY

      - name: Extract AI hints (integration)
        if: always()
        shell: bash
        run: |
          : > ai-hints-integration.txt
          ts="$(date +%H:%M:%S)"
          for f in compose-logs.txt integration-pytest.log compose-up.txt compose-build.txt; do
            [ -f "$f" ] || continue
            grep -E '(Traceback|ERROR|CRITICAL|Exception|ValueError|not enough values to unpack|connection refused|pg_isready|curl:|panic|segmentation|Address already in use)' "$f" | sed "s/^/$ts /" >> ai-hints-integration.txt || true
          done
          if [ ! -s ai-hints-integration.txt ]; then echo 'no obvious errors found' > ai-hints-integration.txt; fi
          {
            echo '## AI hints (integration)'
            echo
            echo '```'
            tail -n 40 ai-hints-integration.txt
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts (integration)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-integration
          path: |
            compose-ps.txt
            compose-logs.txt
            compose-up.txt
            compose-build.txt
            integration-pytest.log
            ai-hints-integration.txt
            none.txt
          if-no-files-found: ignore
  mirror_logs:
    needs: [unit, integration]
    if: ${{ always() && github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
        with:
          ref: ${{ github.head_ref }}

      - uses: actions/download-artifact@v4
        with:
          pattern: ci-logs-*
          merge-multiple: true

      - name: Sanitize logs to tmp directory
        id: sanitize
        shell: bash
        run: |
          rm -rf logs_sanitized && mkdir -p logs_sanitized
          python - <<'PY'
          import os,re,glob,io,sys,shutil,json
          os.makedirs("logs_sanitized", exist_ok=True)
          files = sorted(glob.glob("*.log")+glob.glob("*.txt"))
          rules = [
            (re.compile(r'(?i)\b(PG_PASSWORD|POSTGRES_PASSWORD|REDIS_PASSWORD|MINIO_SECRET_KEY|AWS_SECRET_ACCESS_KEY|OPENAI_API_KEY|API_KEY|SECRET|TOKEN|PASSWORD)\s*=\s*[^\s]+'), r'\1=<redacted>'),
            (re.compile(r'(?i)\bDATABASE_URL\s*=\s*\S+'), 'DATABASE_URL=<redacted>'),
            (re.compile(r'postgres(?:ql|\+psycopg)?://([^:@/]+):([^@/]+)@'), r'postgresql://\1:<redacted>@'),
            (re.compile(r'://([^:@/]+):([^@/]+)@'), r'://\1:<redacted>@'),
            (re.compile(r'Bearer\s+[A-Za-z0-9\-._~+/]+=*'), 'Bearer <redacted>'),
            (re.compile(r'(?i)(Authorization:\s*)\S+'), r'\1<redacted>')
          ]
          for src in files:
            try:
              data = open(src,'r',errors='ignore').read()
            except Exception:
              continue
            red = data
            for pat, sub in rules:
              red = pat.sub(sub, red)
            with open(os.path.join("logs_sanitized", os.path.basename(src)), "w", encoding="utf-8") as f:
              f.write(red)
          PY
          echo "dir=logs_sanitized" >> $GITHUB_OUTPUT

      - name: Remove raw logs to avoid accidental use
        shell: bash
        run: |
          SAN="${{ steps.sanitize.outputs.dir }}"
          find . -maxdepth 1 -type f \( -name "*.log" -o -name "*.txt" \) -not -path "./$SAN/*" -delete || true

      - name: Build sanitized digest (pass 1)
        id: digest1
        shell: bash
        env:
          SAN_DIR: ${{ steps.sanitize.outputs.dir }}
        run: |
          python - <<'PY'
          import os,re,glob,io,sys,json,math
          san=os.environ.get("SAN_DIR","logs_sanitized")
          files=[("compose-logs.txt","compose-logs.txt"),
                 ("integration-pytest.log","integration-pytest.log"),
                 ("compose-up.txt","compose-up.txt"),
                 ("compose-build.txt","compose-build.txt"),
                 ("unit-pytest.log","unit-pytest.log"),
                 ("web-vitest.log","web-vitest.log"),
                 ("webapp-build.log","webapp-build.log")]
          err_pat=re.compile(r"(Traceback \(most recent call last\):|ERROR|FATAL|authentication failed|Exception|ImportError|ModuleNotFoundError|OperationalError|Connection refused|ValueError|TypeError)",re.I)

          def load(name):
              p=os.path.join(san,name)
              if not os.path.exists(p): return name,None
              with open(p,"r",errors="ignore") as f: return name,f.read()

          def last_traceback(txt):
              if not txt: return ""
              idx=[m.start() for m in re.finditer(r"Traceback \(most recent call last\):",txt)]
              if idx: return txt[idx[-1]:].splitlines()[:200]
              lines=[l for l in txt.splitlines() if err_pat.search(l)]
              return lines[-60:] if lines else []

          def section(title,lines):
              if not lines: return ""
              b=["<details><summary>%s — %d lines</summary>"% (title,len(lines)),"","```"]
              b.extend(lines); b.extend(["```","","</details>",""])
              return "\n".join(b)

          TAIL=300
          def render(max_total=60000, tail=TAIL):
              parts=["<!-- CI_LOG_MIRROR -->","### CI last run logs (sanitized)",""]
              for fname,label in files:
                  name,txt=load(fname)
                  if txt is None: continue
                  err=last_traceback(txt)
                  if err: parts.append(section(label+" — Errors",err))
                  tail_lines=txt.splitlines()[-tail:] if tail>0 else []
                  if tail_lines: parts.append(section(label+" — Tail",tail_lines))
              body="\n".join(parts)
              return body

          body=render()
          open("pr_comment.md","w",encoding="utf-8").write(body)
          open("pr_len.txt","w").write(str(len(body)))
          PY
          echo "len=$(cat pr_len.txt)" >> $GITHUB_OUTPUT

      - name: Shrink digest if needed (pass 2)
        if: ${{ steps.digest1.outputs.len && fromJSON(steps.digest1.outputs.len) > 60000 }}
        id: digest2
        shell: bash
        env:
          SAN_DIR: ${{ steps.sanitize.outputs.dir }}
        run: |
          python - <<'PY'
          import os,re
          san=os.environ.get("SAN_DIR","logs_sanitized")
          with open("pr_comment.md","r",errors="ignore") as f: body=f.read()
          if len(body)<=60000:
              raise SystemExit
          def rebuild(tail):
              files=[("compose-logs.txt","compose-logs.txt"),
                     ("integration-pytest.log","integration-pytest.log"),
                     ("compose-up.txt","compose-up.txt"),
                     ("compose-build.txt","compose-build.txt"),
                     ("unit-pytest.log","unit-pytest.log"),
                     ("web-vitest.log","web-vitest.log"),
                     ("webapp-build.log","webapp-build.log")]
              err_pat=re.compile(r"(Traceback \(most recent call last\):|ERROR|FATAL|authentication failed|Exception|ImportError|ModuleNotFoundError|OperationalError|Connection refused|ValueError|TypeError)",re.I)
              def load(name):
                  p=os.path.join(san,name)
                  if not os.path.exists(p): return name,None
                  return name,open(p,"r",errors="ignore").read()
              def last_tb(txt):
                  if not txt: return []
                  idx=[m.start() for m in re.finditer(r"Traceback \(most recent call last\):",txt)]
                  if idx: return txt[idx[-1]:].splitlines()[:200]
                  lines=[l for l in txt.splitlines() if err_pat.search(l)]
                  return lines[-60:] if lines else []
              def section(title,lines):
                  if not lines: return ""
                  b=["<details><summary>%s — %d lines</summary>"% (title,len(lines)),"","```"]
                  b.extend(lines); b.extend(["```","","</details>",""])
                  return "\n".join(b)
              parts=["<!-- CI_LOG_MIRROR -->","### CI last run logs (sanitized)",""]
              for fname,label in files:
                  name,txt=load(fname)
                  if txt is None: continue
                  err=last_tb(txt)
                  if err: parts.append(section(label+" — Errors",err))
                  tl=txt.splitlines()[-tail:] if tail>0 else []
                  if tl: parts.append(section(label+" — Tail",tl))
              return "\n".join(parts)
          for tail in (200,120,80,0):
              b=rebuild(tail)
              if len(b)<=60000:
                  open("pr_comment.md","w",encoding="utf-8").write(b)
                  break
          else:
              idx=["<!-- CI_LOG_MIRROR -->","### CI last run logs (sanitized)","","Logs are too large; showing Errors only."]
              open("pr_comment.md","w",encoding="utf-8").write("\n".join(idx))
          PY

      - name: Upsert PR comment (sanitized digest)
        uses: actions/github-script@v7
        env:
          BODY_PATH: pr_comment.md
        with:
          script: |
            const fs=require('fs'); const {owner,repo}=context.repo;
            const issue_number=context.issue.number; const marker='<!-- CI_LOG_MIRROR -->';
            const body=fs.readFileSync(process.env.BODY_PATH,'utf8');
            const len=body.length;
            const comments=await github.rest.issues.listComments({owner,repo,issue_number,per_page:100});
            const existing=comments.data.find(c=>c.user.type==='Bot' && c.body && c.body.includes(marker));
            if (existing) await github.rest.issues.updateComment({owner,repo,comment_id:existing.id,body});
            else await github.rest.issues.createComment({owner,repo,issue_number,body});
            core.info(`Posted sanitized digest (${len} chars).`)
