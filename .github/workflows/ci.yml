name: ci

on:
  pull_request:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  issues: write

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          cache: 'npm'
          cache-dependency-path: |
            web/package-lock.json
            webapp/package-lock.json

      - name: Install Python dev deps
        shell: bash
        run: |
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Python unit tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m "not integration" 2>&1 | tee unit-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend web tests
        shell: bash
        run: |
          if [ -f web/package.json ]; then
            cd web
            set -o pipefail
            npm ci
            npm test 2>&1 | tee ../web-vitest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend webapp build
        shell: bash
        run: |
          if [ -f webapp/package.json ]; then
            cd webapp
            set -o pipefail
            npm ci
            npm run build 2>&1 | tee ../webapp-build.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Pick tail and write summary
        id: picktail_unit
        if: always()
        shell: bash
        run: |
          PATTERN='Traceback|ERROR|CRITICAL|Exception|AssertionError|TypeError|ReferenceError|TS[0-9]+:|not found|exit code [1-9]'
          candidates=()
          [ -s unit-pytest.log ] && candidates+=("unit-pytest.log")
          [ -s web-vitest.log ] && candidates+=("web-vitest.log")
          [ -s webapp-build.log ] && candidates+=("webapp-build.log")
          pick=""
          for f in "${candidates[@]}"; do
            if grep -Eq "$PATTERN" "$f"; then pick="$f"; break; fi
          done
          if [ -z "$pick" ] && [ ${#candidates[@]} -gt 0 ]; then
            pick="$(ls -t "${candidates[@]}" | head -n1)"
          fi
          if [ -z "$pick" ]; then
            echo "no logs" > none.txt
            pick=none.txt
          fi
          echo "tail_path=$pick" >> $GITHUB_OUTPUT
          {
            echo "## Summary"
            echo
            echo "```"
            tail -n 200 "$pick"
            echo "```"
          } >> $GITHUB_STEP_SUMMARY

      - name: Extract AI hints (unit)
        if: always()
        shell: bash
        run: |
          : > ai-hints-unit.txt
          ts="$(date +%H:%M:%S)"
          for f in unit-pytest.log web-vitest.log webapp-build.log; do
            [ -f "$f" ] || continue
            grep -E '(Traceback|ERROR|CRITICAL|Exception|AssertionError|TypeError|ReferenceError|TS[0-9]+:|not found|exit code [1-9])' "$f" | sed "s/^/$ts /" >> ai-hints-unit.txt || true
          done
          if [ ! -s ai-hints-unit.txt ]; then echo 'no obvious errors found' > ai-hints-unit.txt; fi
          {
            echo '## AI hints (unit)'
            echo
            echo '```'
            tail -n 40 ai-hints-unit.txt
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts (unit)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-unit
          path: |
            unit-pytest.log
            web-vitest.log
            webapp-build.log
            ai-hints-unit.txt
            none.txt
          if-no-files-found: ignore

      - name: Upsert failure comment (unit)
        if: failure() && github.event_name == 'pull_request'
        continue-on-error: true
        env:
          TAIL_PATH: ${{ steps.picktail_unit.outputs.tail_path }}
          TITLE: "CI / unit"
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const marker = '<!-- CI_FAILURE_SUMMARY -->';
            let tail = 'no logs';
            let hints = 'no logs';
            try { tail = fs.readFileSync(process.env.TAIL_PATH, 'utf8'); } catch (e) {}
            try { hints = fs.readFileSync('ai-hints-unit.txt', 'utf8'); } catch (e) {}
            const tail_snippet = tail.split('\n').slice(-200).join('\n');
            const hints_snippet = hints.split('\n').slice(-40).join('\n');
            const body = [
              marker,
              process.env.TITLE,
              '',
              '```',
              tail_snippet || 'no logs',
              '```',
              '',
              '## AI hints',
              '',
              '```',
              hints_snippet || 'no logs',
              '```',
              '',
              'Reply with `@codex review` to request an AI patch.'
            ].join('\n');
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body && c.body.includes(marker));
            if (existing) {
              await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body});
            } else {
              await github.rest.issues.createComment({owner, repo, issue_number, body});
            }

      - name: Delete failure comment on success (unit)
        if: success() && github.event_name == 'pull_request'
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const marker = '<!-- CI_FAILURE_SUMMARY -->';
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body && c.body.includes(marker));
            if (existing) {
              await github.rest.issues.deleteComment({owner, repo, comment_id: existing.id});
            }
  integration:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: unit
    steps:
      - uses: actions/checkout@v4

      - name: Prepare .env.ci
        shell: bash
        run: |
          printf "PG_HOST=postgres\nPG_PORT=5432\nPG_USER=%s\nPG_PASSWORD=%s\nPG_DATABASE=%s\nPOSTGRES_HOST=postgres\nPOSTGRES_PORT=5432\nPOSTGRES_USER=%s\nPOSTGRES_PASSWORD=%s\nPOSTGRES_DB=%s\nDATABASE_URL=postgresql://%s:%s@postgres:5432/%s\n" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" > .env.ci

      - name: Build images
        shell: bash
        run: |
          export COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci build --pull 2>&1 | tee compose-build.txt
          exit ${PIPESTATUS[0]}

      - name: Up services
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci up -d --wait 2>&1 | tee compose-up.txt
          exit ${PIPESTATUS[0]}

      - name: Dump compose logs
        if: always()
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          docker compose $COMPOSE_FILES --env-file .env.ci ps > compose-ps.txt || true
          docker compose $COMPOSE_FILES --env-file .env.ci logs --no-color > compose-logs.txt || true

      - name: Python integration tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m integration 2>&1 | tee integration-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Pick tail and write summary
        id: picktail_integration
        if: always()
        shell: bash
        run: |
          PATTERN='Traceback|ERROR|CRITICAL|Exception|ValueError|not enough values to unpack|connection refused|pg_isready|curl:|panic|segmentation|Address already in use'
          candidates=()
          [ -s compose-logs.txt ] && candidates+=("compose-logs.txt")
          [ -s integration-pytest.log ] && candidates+=("integration-pytest.log")
          [ -s compose-up.txt ] && candidates+=("compose-up.txt")
          [ -s compose-build.txt ] && candidates+=("compose-build.txt")
          pick=""
          for f in "${candidates[@]}"; do
            if grep -Eq "$PATTERN" "$f"; then pick="$f"; break; fi
          done
          if [ -z "$pick" ] && [ ${#candidates[@]} -gt 0 ]; then
            pick="$(ls -t "${candidates[@]}" | head -n1)"
          fi
          if [ -z "$pick" ]; then
            echo "no logs" > none.txt
            pick=none.txt
          fi
          echo "tail_path=$pick" >> $GITHUB_OUTPUT
          {
            echo "## Summary"
            echo
            echo "```"
            tail -n 200 "$pick"
            echo "```"
          } >> $GITHUB_STEP_SUMMARY

      - name: Extract AI hints (integration)
        if: always()
        shell: bash
        run: |
          : > ai-hints-integration.txt
          ts="$(date +%H:%M:%S)"
          for f in compose-logs.txt integration-pytest.log compose-up.txt compose-build.txt; do
            [ -f "$f" ] || continue
            grep -E '(Traceback|ERROR|CRITICAL|Exception|ValueError|not enough values to unpack|connection refused|pg_isready|curl:|panic|segmentation|Address already in use)' "$f" | sed "s/^/$ts /" >> ai-hints-integration.txt || true
          done
          if [ ! -s ai-hints-integration.txt ]; then echo 'no obvious errors found' > ai-hints-integration.txt; fi
          {
            echo '## AI hints (integration)'
            echo
            echo '```'
            tail -n 40 ai-hints-integration.txt
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts (integration)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-integration
          path: |
            compose-ps.txt
            compose-logs.txt
            compose-up.txt
            compose-build.txt
            integration-pytest.log
            ai-hints-integration.txt
            none.txt
          if-no-files-found: ignore

      - name: Upsert failure comment (integration)
        if: failure() && github.event_name == 'pull_request'
        continue-on-error: true
        env:
          TAIL_PATH: ${{ steps.picktail_integration.outputs.tail_path }}
          TITLE: "CI / integration"
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const marker = '<!-- CI_FAILURE_SUMMARY -->';
            let tail = 'no logs';
            let hints = 'no logs';
            try { tail = fs.readFileSync(process.env.TAIL_PATH, 'utf8'); } catch (e) {}
            try { hints = fs.readFileSync('ai-hints-integration.txt', 'utf8'); } catch (e) {}
            const tail_snippet = tail.split('\n').slice(-200).join('\n');
            const hints_snippet = hints.split('\n').slice(-40).join('\n');
            const body = [
              marker,
              process.env.TITLE,
              '',
              '```',
              tail_snippet || 'no logs',
              '```',
              '',
              '## AI hints',
              '',
              '```',
              hints_snippet || 'no logs',
              '```',
              '',
              'Reply with `@codex review` to request an AI patch.'
            ].join('\n');
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body && c.body.includes(marker));
            if (existing) {
              await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body});
            } else {
              await github.rest.issues.createComment({owner, repo, issue_number, body});
            }

      - name: Delete failure comment on success (integration)
        if: success() && github.event_name == 'pull_request'
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const marker = '<!-- CI_FAILURE_SUMMARY -->';
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body && c.body.includes(marker));
            if (existing) {
              await github.rest.issues.deleteComment({owner, repo, comment_id: existing.id});
            }
  mirror_logs:
    needs: [unit, integration]
    if: ${{ always() && github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository }}
    runs-on: ubuntu-latest
    steps:
      - name: Download all CI log artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: ci-logs-*
          merge-multiple: true

      - name: Sanitize logs to tmp directory
        id: sanitize
        shell: bash
        run: |
          rm -rf logs_sanitized && mkdir -p logs_sanitized
          python - <<'PY'
          import os,re,glob,io,sys,shutil,json
          os.makedirs("logs_sanitized", exist_ok=True)
          files = sorted(glob.glob("*.log")+glob.glob("*.txt"))
          rules = [
            (re.compile(r'(?i)\b(PG_PASSWORD|POSTGRES_PASSWORD|REDIS_PASSWORD|MINIO_SECRET_KEY|AWS_SECRET_ACCESS_KEY|OPENAI_API_KEY|API_KEY|SECRET|TOKEN|PASSWORD)\s*=\s*[^\s]+'), r'\1=<redacted>'),
            (re.compile(r'(?i)\bDATABASE_URL\s*=\s*\S+'), 'DATABASE_URL=<redacted>'),
            (re.compile(r'postgres(?:ql|\+psycopg)?://([^:@/]+):([^@/]+)@'), r'postgresql://\1:<redacted>@'),
            (re.compile(r'://([^:@/]+):([^@/]+)@'), r'://\1:<redacted>@'),
            (re.compile(r'Bearer\s+[A-Za-z0-9\-._~+/]+=*'), 'Bearer <redacted>'),
            (re.compile(r'(?i)(Authorization:\s*)\S+'), r'\1<redacted>')
          ]
          for src in files:
            try:
              data = open(src,'r',errors='ignore').read()
            except Exception:
              continue
            red = data
            for pat, sub in rules:
              red = pat.sub(sub, red)
            with open(os.path.join("logs_sanitized", os.path.basename(src)), "w", encoding="utf-8") as f:
              f.write(red)
          PY
          echo "dir=logs_sanitized" >> $GITHUB_OUTPUT

      - name: Remove raw logs to avoid accidental use
        shell: bash
        run: |
          SAN="${{ steps.sanitize.outputs.dir }}"
          find . -maxdepth 1 -type f \( -name "*.log" -o -name "*.txt" \) -not -path "./$SAN/*" -delete || true

      - name: Build PR comment body
        id: body
        shell: bash
        env:
          SAN_DIR: ${{ steps.sanitize.outputs.dir }}
        run: |
          marker="<!-- CI_LOG_MIRROR -->"
          title="CI last run logs (sanitized)"
          section () {
            f="$1"; label="$2"
            [ -s "$f" ] || return 0
            echo "<details><summary>${label} — $(wc -l < "$f") lines</summary>"
            echo
            echo '```'
            sed -e 's/\r$//' "$f"
            echo '```'
            echo
            echo '</details>'
            echo
          }
          {
            echo "$marker"
            echo "### ${title}"
            echo
            section "$SAN_DIR/compose-logs.txt"        "compose-logs.txt"
            section "$SAN_DIR/integration-pytest.log"  "integration-pytest.log"
            section "$SAN_DIR/compose-up.txt"          "compose-up.txt"
            section "$SAN_DIR/compose-build.txt"       "compose-build.txt"
            section "$SAN_DIR/unit-pytest.log"         "unit-pytest.log"
            section "$SAN_DIR/web-vitest.log"          "web-vitest.log"
            section "$SAN_DIR/webapp-build.log"        "webapp-build.log"
            echo "> Reply with \`@codex review\` to request an AI patch."
          } > pr_comment.md
          echo "path=pr_comment.md" >> $GITHUB_OUTPUT

      - name: Upsert PR comment with full logs (sanitized)
        uses: actions/github-script@v7
        env:
          BODY_PATH: ${{ steps.body.outputs.path }}
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const marker = '<!-- CI_LOG_MIRROR -->';
            const body = fs.readFileSync(process.env.BODY_PATH, 'utf8');
            const comments = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = comments.data.find(c => c.user.type === 'Bot' && c.body && c.body.includes(marker));
            if (existing) {
              await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body});
            } else {
              await github.rest.issues.createComment({owner, repo, issue_number, body});
            }
