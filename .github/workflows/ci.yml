name: ci

on:
  pull_request:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  issues: write

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          cache: 'npm'
          cache-dependency-path: |
            web/package-lock.json
            webapp/package-lock.json

      - name: Install Python dev deps
        shell: bash
        run: |
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Python unit tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m "not integration" 2>&1 | tee unit-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend web tests
        shell: bash
        run: |
          if [ -f web/package.json ]; then
            cd web
            set -o pipefail
            npm ci
            npm test 2>&1 | tee ../web-vitest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend webapp build
        shell: bash
        run: |
          if [ -f webapp/package.json ]; then
            cd webapp
            set -o pipefail
            npm ci
            NODE_ENV=production npm run build 2>&1 | tee ../webapp-build.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Pick tail and write summary
        id: picktail_unit
        if: always()
        shell: bash
        run: |
          PATTERN='Traceback|ERROR|CRITICAL|Exception|AssertionError|TypeError|ReferenceError|TS[0-9]+:|not found|exit code [1-9]'
          candidates=()
          [ -s unit-pytest.log ] && candidates+=("unit-pytest.log")
          [ -s web-vitest.log ] && candidates+=("web-vitest.log")
          [ -s webapp-build.log ] && candidates+=("webapp-build.log")
          pick=""
          for f in "${candidates[@]}"; do
            if grep -Eq "$PATTERN" "$f"; then pick="$f"; break; fi
          done
          if [ -z "$pick" ] && [ ${#candidates[@]} -gt 0 ]; then
            pick="$(ls -t "${candidates[@]}" | head -n1)"
          fi
          if [ -z "$pick" ]; then
            echo "no logs" > none.txt
            pick=none.txt
          fi
          echo "tail_path=$pick" >> $GITHUB_OUTPUT
          {
            echo "## Summary"
            echo
            echo "```"
            tail -n 200 "$pick"
            echo "```"
          } >> $GITHUB_STEP_SUMMARY

      - name: Extract AI hints (unit)
        if: always()
        shell: bash
        run: |
          : > ai-hints-unit.txt
          ts="$(date +%H:%M:%S)"
          for f in unit-pytest.log web-vitest.log webapp-build.log; do
            [ -f "$f" ] || continue
            grep -E '(Traceback|ERROR|CRITICAL|Exception|AssertionError|TypeError|ReferenceError|TS[0-9]+:|not found|exit code [1-9])' "$f" | sed "s/^/$ts /" >> ai-hints-unit.txt || true
          done
          if [ ! -s ai-hints-unit.txt ]; then echo 'no obvious errors found' > ai-hints-unit.txt; fi
          {
            echo '## AI hints (unit)'
            echo
            echo '```'
            tail -n 40 ai-hints-unit.txt
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts (unit)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-unit
          path: |
            unit-pytest.log
            web-vitest.log
            webapp-build.log
            ai-hints-unit.txt
            none.txt
          if-no-files-found: ignore
  integration:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: unit
    steps:
      - uses: actions/checkout@v5

      - name: Prepare .env.ci
        shell: bash
        run: |
          printf "PG_HOST=postgres\nPG_PORT=5432\nPG_USER=%s\nPG_PASSWORD=%s\nPG_DATABASE=%s\nPOSTGRES_HOST=postgres\nPOSTGRES_PORT=5432\nPOSTGRES_USER=%s\nPOSTGRES_PASSWORD=%s\nPOSTGRES_DB=%s\nDATABASE_URL=postgresql://%s:%s@postgres:5432/%s\n" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" > .env.ci

      - name: Build images
        shell: bash
        run: |
          export COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci build --pull 2>&1 | tee compose-build.txt
          exit ${PIPESTATUS[0]}

      - name: Up services
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci up -d --wait 2>&1 | tee compose-up.txt
          exit ${PIPESTATUS[0]}

      - name: Dump compose logs
        if: always()
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          docker compose $COMPOSE_FILES --env-file .env.ci ps > compose-ps.txt || true
          docker compose $COMPOSE_FILES --env-file .env.ci logs --no-color > compose-logs.txt || true

      - name: Python integration tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m integration 2>&1 | tee integration-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Pick tail and write summary
        id: picktail_integration
        if: always()
        shell: bash
        run: |
          PATTERN='Traceback|ERROR|CRITICAL|Exception|ValueError|not enough values to unpack|connection refused|pg_isready|curl:|panic|segmentation|Address already in use'
          candidates=()
          [ -s compose-logs.txt ] && candidates+=("compose-logs.txt")
          [ -s integration-pytest.log ] && candidates+=("integration-pytest.log")
          [ -s compose-up.txt ] && candidates+=("compose-up.txt")
          [ -s compose-build.txt ] && candidates+=("compose-build.txt")
          pick=""
          for f in "${candidates[@]}"; do
            if grep -Eq "$PATTERN" "$f"; then pick="$f"; break; fi
          done
          if [ -z "$pick" ] && [ ${#candidates[@]} -gt 0 ]; then
            pick="$(ls -t "${candidates[@]}" | head -n1)"
          fi
          if [ -z "$pick" ]; then
            echo "no logs" > none.txt
            pick=none.txt
          fi
          echo "tail_path=$pick" >> $GITHUB_OUTPUT
          {
            echo "## Summary"
            echo
            echo "```"
            tail -n 200 "$pick"
            echo "```"
          } >> $GITHUB_STEP_SUMMARY

      - name: Extract AI hints (integration)
        if: always()
        shell: bash
        run: |
          : > ai-hints-integration.txt
          ts="$(date +%H:%M:%S)"
          for f in compose-logs.txt integration-pytest.log compose-up.txt compose-build.txt; do
            [ -f "$f" ] || continue
            grep -E '(Traceback|ERROR|CRITICAL|Exception|ValueError|not enough values to unpack|connection refused|pg_isready|curl:|panic|segmentation|Address already in use)' "$f" | sed "s/^/$ts /" >> ai-hints-integration.txt || true
          done
          if [ ! -s ai-hints-integration.txt ]; then echo 'no obvious errors found' > ai-hints-integration.txt; fi
          {
            echo '## AI hints (integration)'
            echo
            echo '```'
            tail -n 40 ai-hints-integration.txt
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts (integration)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-integration
          path: |
            compose-ps.txt
            compose-logs.txt
            compose-up.txt
            compose-build.txt
            integration-pytest.log
            ai-hints-integration.txt
            none.txt
          if-no-files-found: ignore
  mirror_logs:
    # Mirror artifacts and publish a single sanitized log digest comment
    needs: [unit, integration]
    if: ${{ always() && github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
        with:
          ref: ${{ github.head_ref }}

      - name: Resolve PR number
        id: pr
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            let number = context.payload.pull_request?.number || null;
            if (!number) {
              const res = await github.rest.repos.listPullRequestsAssociatedWithCommit({owner, repo, commit_sha: context.sha});
              number = res.data?.[0]?.number || null;
            }
            if (!number) core.setFailed('No PR found for this run');
            core.setOutput('number', number.toString());

      - uses: actions/download-artifact@v4
        with:
          pattern: ci-logs-*
          merge-multiple: true
          if-no-files-found: warn

      - name: Sanitize logs to tmp directory
        id: sanitize
        shell: bash
        run: |
          rm -rf logs_sanitized && mkdir -p logs_sanitized
          python - <<'PY'
          import os,re,glob
          os.makedirs("logs_sanitized", exist_ok=True)
          files = sorted(glob.glob("*.log")+glob.glob("*.txt"))
          rules = [
            (re.compile(r'(?i)\b(PG_PASSWORD|POSTGRES_PASSWORD|REDIS_PASSWORD|MINIO_SECRET_KEY|AWS_SECRET_ACCESS_KEY|OPENAI_API_KEY|API_KEY|SECRET|TOKEN|PASSWORD)\s*=\s*[^\s]+'), r'\1=<redacted>'),
            (re.compile(r'(?i)\bDATABASE_URL\s*=\s*\S+'), 'DATABASE_URL=<redacted>'),
            (re.compile(r'postgres(?:ql|\+psycopg)?://([^:@/]+):([^@/]+)@'), r'postgresql://\1:<redacted>@'),
            (re.compile(r'://([^:@/]+):([^@/]+)@'), r'://\1:<redacted>@'),
            (re.compile(r'Bearer\s+[A-Za-z0-9\-._~+/]+=*'), 'Bearer <redacted>'),
            (re.compile(r'(?i)(Authorization:\s*)\S+'), r'\1<redacted>')
          ]
          for src in files:
            try:
              data = open(src,'r',errors='ignore').read()
            except Exception:
              continue
            red = data
            for pat, sub in rules:
              red = pat.sub(sub, red)
            with open(os.path.join("logs_sanitized", os.path.basename(src)), "w", encoding="utf-8") as f:
              f.write(red)
          PY
          echo "dir=logs_sanitized" >> $GITHUB_OUTPUT

      - name: Remove raw logs to avoid accidental use
        shell: bash
        run: |
          SAN="${{ steps.sanitize.outputs.dir }}"
          find . -maxdepth 1 -type f \( -name "*.log" -o -name "*.txt" \) -not -path "./$SAN/*" -delete || true

      - name: Build sanitized digest
        shell: bash
        env:
          SAN_DIR: ${{ steps.sanitize.outputs.dir }}
        run: |
          python - <<'PY'
          import os,re
          san=os.environ.get("SAN_DIR","logs_sanitized")
          files=[("compose-logs.txt","compose-logs.txt"),
                 ("integration-pytest.log","integration-pytest.log"),
                 ("compose-up.txt","compose-up.txt"),
                 ("compose-build.txt","compose-build.txt"),
                 ("unit-pytest.log","unit-pytest.log"),
                 ("web-vitest.log","web-vitest.log"),
                 ("webapp-build.log","webapp-build.log")]
          err_pat=re.compile(r"(Traceback \(most recent call last\):|ERROR|FATAL|authentication failed|Exception|ImportError|ModuleNotFoundError|OperationalError|Connection refused|ValueError|TypeError)",re.I)
          def load(name):
              p=os.path.join(san,name)
              if not os.path.exists(p): return name,None
              with open(p,"r",errors="ignore") as f: return name,f.read()
          def last_traceback(txt):
              if not txt: return ""
              idx=[m.start() for m in re.finditer(r"Traceback \(most recent call last\):",txt)]
              if idx: return txt[idx[-1]:].splitlines()[:200]
              lines=[l for l in txt.splitlines() if err_pat.search(l)]
              return lines[-60:] if lines else []
          def section(title,lines):
              if not lines: return ""
              b=[f"<details><summary>{title} — {len(lines)} lines</summary>","","```"]
              b.extend(lines); b.extend(["```","","</details>",""])
              return "\n".join(b)
          parts=["<!-- CI_LOG_MIRROR -->","### CI last run logs (sanitized)",""]
          found=False
          for fname,label in files:
              name,txt=load(fname)
              if txt is None: continue
              found=True
              err=last_traceback(txt)
              if err: parts.append(section(label+" — Errors",err))
              tail_lines=txt.splitlines()[-300:]
              if tail_lines: parts.append(section(label+" — Tail",tail_lines))
          if not found:
              parts.append("No artifacts found.")
          body="\n".join(parts)
          open("pr_comment.md","w",encoding="utf-8").write(body)
          PY

      - name: Cap body to 60000 chars
        id: cap
        shell: bash
        run: |
          BODY=pr_comment.md
          LEN=$(wc -c < "$BODY" || echo 0)
          if [ "$LEN" -gt 60000 ]; then
            head -c 60000 "$BODY" > pr_comment.capped.md
            mv pr_comment.capped.md "$BODY"
          fi
          echo "len=$(wc -c < "$BODY")" >> $GITHUB_OUTPUT

      - name: Upsert PR comment (sanitized digest)
        uses: actions/github-script@v7
        env:
          BODY_PATH: pr_comment.md
          PR_NUMBER: ${{ steps.pr.outputs.number }}
        with:
          script: |
            const fs = require('fs');
            const {owner, repo} = context.repo;
            const issue_number = Number(process.env.PR_NUMBER);
            const marker = '<!-- CI_LOG_MIRROR -->';
            let body = fs.readFileSync(process.env.BODY_PATH, 'utf8');
            const list = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = list.data.find(c => c.body && c.body.includes(marker));
            async function postOrUpdate(b) {
              try {
                if (existing) {
                  await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body: b});
                } else {
                  await github.rest.issues.createComment({owner, repo, issue_number, body: b});
                }
              } catch (e) {
                if (e.status === 422) {
                  const trimmed = b.slice(0, 60000);
                  if (existing) {
                    await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body: trimmed});
                  } else {
                    await github.rest.issues.createComment({owner, repo, issue_number, body: trimmed});
                  }
                } else {
                  throw e;
                }
              }
            }
            await postOrUpdate(body);
