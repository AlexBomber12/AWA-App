name: ci

on:
  pull_request:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  issues: write

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          cache: 'npm'
          cache-dependency-path: |
            web/package-lock.json
            webapp/package-lock.json

      - name: Install Python dev deps
        shell: bash
        run: |
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Python unit tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m "not integration" 2>&1 | tee unit-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend web tests
        shell: bash
        run: |
          if [ -f web/package.json ]; then
            cd web
            set -o pipefail
            npm ci
            npm test 2>&1 | tee ../web-vitest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Frontend webapp build
        shell: bash
        run: |
          if [ -f webapp/package.json ]; then
            cd webapp
            set -o pipefail
            npm ci
            npm run build 2>&1 | tee ../webapp-build.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Upload artifacts (unit)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-unit
          path: |
            unit-pytest.log
            web-vitest.log
            webapp-build.log
          if-no-files-found: ignore
  integration:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: unit
    steps:
      - uses: actions/checkout@v5

      - name: Prepare .env.ci
        shell: bash
        run: |
          printf "PG_HOST=postgres\nPG_PORT=5432\nPG_USER=%s\nPG_PASSWORD=%s\nPG_DATABASE=%s\nPOSTGRES_HOST=postgres\nPOSTGRES_PORT=5432\nPOSTGRES_USER=%s\nPOSTGRES_PASSWORD=%s\nPOSTGRES_DB=%s\nDATABASE_URL=postgresql://%s:%s@postgres:5432/%s\n" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" "${{ secrets.PG_USER || 'postgres' }}" "${{ secrets.PG_PASSWORD || 'pass' }}" "${{ secrets.PG_DATABASE || 'awa' }}" > .env.ci

      - name: Build images
        shell: bash
        run: |
          export COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci build --pull 2>&1 | tee compose-build.txt
          exit ${PIPESTATUS[0]}

      - name: Up services
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          set -o pipefail
          docker compose $COMPOSE_FILES --env-file .env.ci up -d --wait 2>&1 | tee compose-up.txt
          exit ${PIPESTATUS[0]}

      - name: Dump compose logs
        if: always()
        shell: bash
        run: |
          COMPOSE_FILES=""
          [ -f docker-compose.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.yml"
          [ -f docker-compose.ci.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.ci.yml"
          [ -f docker-compose.postgres.yml ] && COMPOSE_FILES="$COMPOSE_FILES -f docker-compose.postgres.yml"
          docker compose $COMPOSE_FILES --env-file .env.ci ps > compose-ps.txt || true
          docker compose $COMPOSE_FILES --env-file .env.ci logs --no-color > compose-logs.txt || true

      - name: Python integration tests
        shell: bash
        run: |
          if [ -f pyproject.toml ] || [ -f pytest.ini ]; then
            set -o pipefail
            pytest -q -m integration 2>&1 | tee integration-pytest.log
            exit ${PIPESTATUS[0]}
          fi

      - name: Upload artifacts (integration)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-logs-${{ github.run_id }}-${{ github.run_attempt }}-integration
          path: |
            compose-ps.txt
            compose-logs.txt
            compose-up.txt
            compose-build.txt
            integration-pytest.log
          if-no-files-found: ignore
  mirror_logs:
    needs: [unit, integration]
    if: ${{ always() && github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository }}
    runs-on: ubuntu-latest
    steps:
      - name: Resolve PR number
        id: pr
        uses: actions/github-script@v7
        with:
          script: |
            const {owner, repo} = context.repo;
            let number = context.payload.pull_request?.number || null;
            if (!number) {
              const r = await github.rest.repos.listPullRequestsAssociatedWithCommit({owner, repo, commit_sha: context.sha});
              number = r.data?.[0]?.number || null;
            }
            if (!number) core.setFailed('No PR found for this run');
            core.setOutput('number', String(number));

      - name: Download all CI logs artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: ci-logs-*
          merge-multiple: true

      - name: Sanitize logs
        id: sanitize
        shell: bash
        run: |
          rm -rf logs_sanitized && mkdir -p logs_sanitized
          python - <<'PY'
          import os,re,glob
          os.makedirs("logs_sanitized", exist_ok=True)
          files = sorted(glob.glob("*.log")+glob.glob("*.txt"))
          rules = [
            (re.compile(r'(?i)\b(PG_PASSWORD|POSTGRES_PASSWORD|REDIS_PASSWORD|MINIO_SECRET_KEY|AWS_SECRET_ACCESS_KEY|OPENAI_API_KEY|API_KEY|SECRET|TOKEN|PASSWORD)\s*=\s*[^\s]+'), r'\1=<redacted>'),
            (re.compile(r'(?i)\bDATABASE_URL\s*=\s*\S+'), 'DATABASE_URL=<redacted>'),
            (re.compile(r'postgres(?:ql|\+psycopg)?://([^:@/]+):([^@/]+)@'), r'postgresql://\1:<redacted>@'),
            (re.compile(r'://([^:@/]+):([^@/]+)@'), r'://\1:<redacted>@'),
            (re.compile(r'Bearer\s+[A-Za-z0-9\-._~+/]+=*'), 'Bearer <redacted>'),
            (re.compile(r'(?i)(Authorization:\s*)\S+'), r'\1<redacted>')
          ]
          for src in files:
            try:
              t=open(src,'r',errors='ignore').read()
            except: continue
            for p,s in rules: t=p.sub(s,t)
            open(os.path.join("logs_sanitized", os.path.basename(src)),'w',encoding='utf-8').write(t)
          PY
          echo "dir=logs_sanitized" >> $GITHUB_OUTPUT

      - name: Build PR comment body (error-first, size-capped)
        id: body
        shell: bash
        env:
          SAN_DIR: ${{ steps.sanitize.outputs.dir }}
        run: |
          python - <<'PY' > pr_comment.md
          import os,re

          SAN=os.environ.get("SAN_DIR","logs_sanitized")
          MARKER="<!-- CI_LOG_MIRROR -->"
          HEADING="### CI last run logs (sanitized)"
          MAX=60000

          files=[ # priority order
            ("compose-logs.txt","compose-logs.txt"),
            ("integration-pytest.log","integration-pytest.log"),
            ("compose-up.txt","compose-up.txt"),
            ("compose-build.txt","compose-build.txt"),
            ("unit-pytest.log","unit-pytest.log"),
            ("web-vitest.log","web-vitest.log"),
            ("webapp-build.log","webapp-build.log"),
          ]

          err_pat=re.compile(r"(Traceback \(most recent call last\):|ERROR|FATAL|authentication failed|Exception|ImportError|ModuleNotFoundError|OperationalError|Connection refused|ValueError|TypeError)",re.I)

          def load(name):
            p=os.path.join(SAN,name)
            if not os.path.exists(p): return None
            return open(p,"r",errors="ignore").read()

          def last_trace_or_errors(txt, keep=200, fallback=60):
            if not txt: return []
            idx=[m.start() for m in re.finditer(r"Traceback \(most recent call last\):",txt)]
            if idx:
              return txt[idx[-1]:].splitlines()[:keep]
            lines=[l for l in txt.splitlines() if err_pat.search(l)]
            return lines[-fallback:] if lines else []

          def build(tail_lines_per_file=300, err_cap=200, err_fallback=60, only_crit=False):
            parts=[MARKER, HEADING, ""]
            errors=[]
            tails=[]
            for fname,label in files:
              txt=load(fname)
              if not txt: continue
              err=last_trace_or_errors(txt, keep=err_cap, fallback=err_fallback)
              if err:
                errors.append(("<details><summary>%s — Errors — %d lines</summary>\n\n```\n%s\n```\n\n</details>\n" %
                               (label, len(err), "\n".join(err))))
              if not only_crit and tail_lines_per_file>0:
                tail=txt.splitlines()[-tail_lines_per_file:]
                if tail:
                  tails.append(("<details><summary>%s — Tail — %d lines</summary>\n\n```\n%s\n```\n\n</details>\n" %
                                (label, len(tail), "\n".join(tail))))
            parts.extend(errors)
            parts.extend(tails)
            body="\n".join(parts)
            return body

          for tail in (300,200,120,80,40,0):
            body=build(tail_lines_per_file=tail)
            if len(body)<=MAX:
              open("pr_comment.md","w",encoding="utf-8").write(body)
              break
          else:
            for err_cap in (160,120,80,40):
              body=build(tail_lines_per_file=0, err_cap=err_cap, err_fallback=40)
              if len(body)<=MAX:
                open("pr_comment.md","w",encoding="utf-8").write(body)
                break
            else:
              body=build(tail_lines_per_file=0, err_cap=80, err_fallback=40, only_crit=True)
              if len(body)>MAX: body=body[:MAX]
              open("pr_comment.md","w",encoding="utf-8").write(body)
          PY
          echo "path=pr_comment.md" >> $GITHUB_OUTPUT

      - name: Upsert PR comment (by marker OR heading; 422-safe)
        uses: actions/github-script@v7
        env:
          BODY_PATH: ${{ steps.body.outputs.path }}
          PR_NUMBER: ${{ steps.pr.outputs.number }}
        with:
          script: |
            const fs=require('fs');
            const {owner, repo} = context.repo;
            const issue_number = Number(process.env.PR_NUMBER);
            const marker  = '<!-- CI_LOG_MIRROR -->';
            const heading = '### CI last run logs (sanitized)';
            const body    = fs.readFileSync(process.env.BODY_PATH,'utf8');
            const list = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const existing = list.data.find(c => (c.body||'').includes(marker) || (c.body||'').includes(heading));
            async function upsert(b){
              try{
                if (existing) await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body:b});
                else await github.rest.issues.createComment({owner, repo, issue_number, body:b});
              }catch(e){
                if (e.status===422){
                  const t=b.slice(0,60000);
                  if (existing) await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body:t});
                  else await github.rest.issues.createComment({owner, repo, issue_number, body:t});
                } else { throw e; }
              }
            }
            await upsert(body);

      - name: Verify digest comment
        if: always()
        uses: actions/github-script@v7
        env:
          PR_NUMBER: ${{ steps.pr.outputs.number }}
        with:
          script: |
            const {owner, repo} = context.repo;
            const issue_number = Number(process.env.PR_NUMBER);
            const list = await github.rest.issues.listComments({owner, repo, issue_number, per_page: 100});
            const found = list.data.find(c => (c.body||'').includes('CI last run logs (sanitized)'));
            core.summary.addHeading('CI log digest comment', 2);
            core.summary.addRaw(found ? `Found id=${found.id}, length=${found.body.length}` : 'Not found').write();
