name: Collect all workflow logs

on:
  push:
    branches: [main, dev]
    paths-ignore:
      - 'ci-logs/**'
  workflow_dispatch:
    inputs:
      sha:
        description: 'Commit SHA to collect (optional; defaults to this workflow SHA)'
        required: false
        type: string

permissions:
  actions: read
  contents: write

concurrency:
  group: collect-logs-${{ github.ref_name }}-${{ inputs.sha || github.sha }}
  cancel-in-progress: true

jobs:
  collect:
    # Skip PRs from forks (no write perms)
    if: github.event_name != 'pull_request'
    runs-on: ubuntu-latest
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      OWNER_REPO: ${{ github.repository }}
      HEAD_SHA: ${{ inputs.sha || github.sha }}
      HEAD_BRANCH: ${{ github.ref_name }}

    steps:
      - name: Checkout branch
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ env.HEAD_BRANCH }}

      - name: Wait for all other workflows on this SHA to finish
        shell: bash
        run: |
          set -Eeuo pipefail
          python3 - <<'PY'
          import os, json, urllib.request, urllib.parse, time
          repo = os.environ['OWNER_REPO']
          sha = os.environ['HEAD_SHA']
          self_name = os.environ['GITHUB_WORKFLOW']  # this workflow name
          headers = {
              'Authorization': f"Bearer {os.environ['GH_TOKEN']}",
              'Accept': 'application/vnd.github+json',
              'X-GitHub-Api-Version': '2022-11-28',
              'User-Agent': 'gha-log-collector',
          }
          def api(path, params=None):
              if params:
                  path = f"{path}?{urllib.parse.urlencode(params)}"
              req = urllib.request.Request(f'https://api.github.com/{path}', headers=headers)
              with urllib.request.urlopen(req) as r:
                  return json.load(r)
          deadline = time.time() + 20*60  # 20 minutes
          while True:
              runs = api(f'repos/{repo}/actions/runs', {'head_sha': sha, 'per_page': 100}).get('workflow_runs', [])
              pending = []
              for r in runs:
                  if (r.get('name') or '') == self_name:
                      continue  # exclude self by name
                  if (r.get('status') or '').lower() != 'completed':
                      pending.append((r.get('name'), r.get('id'), r.get('status')))
              if not pending or time.time() > deadline:
                  break
              time.sleep(15)
          PY

      - name: Fetch and unpack workflow logs
        shell: bash
        run: |
          set -Eeuo pipefail
          python3 - <<'PY'
          import os, json, urllib.request, urllib.parse, io, zipfile, pathlib, shutil, time
          from urllib.error import HTTPError

          repo        = os.environ['OWNER_REPO']
          sha         = os.environ['HEAD_SHA']
          branch      = os.environ['HEAD_BRANCH']
          self_run_id = os.environ.get('GITHUB_RUN_ID')  # exclude current run by ID

          headers = {
              'Authorization': f"Bearer {os.environ['GH_TOKEN']}",
              'Accept': 'application/vnd.github+json',
              'X-GitHub-Api-Version': '2022-11-28',
              'User-Agent': 'gha-log-collector',
          }

          def api(path, params=None, raw=False):
              if params:
                  path = f"{path}?{urllib.parse.urlencode(params)}"
              req = urllib.request.Request(f'https://api.github.com/{path}', headers=headers)
              with urllib.request.urlopen(req) as r:
                  return r.read() if raw else json.load(r)

          runs = api(f'repos/{repo}/actions/runs', {'head_sha': sha, 'per_page': 100})['workflow_runs']
          root = pathlib.Path('ci-logs') / branch / sha
          root.mkdir(parents=True, exist_ok=True)

          for r in runs:
              rid    = str(r['id'])
              name   = (r.get('name') or 'run').replace(' ', '_').lower()
              rn     = r.get('run_number') or 0
              status = (r.get('status') or '').lower()
              if rid == str(self_run_id) or status != 'completed':
                  # Skip our own run and any run not yet archived â€” prevents 404
                  continue

              url = f"repos/{repo}/actions/runs/{rid}/logs"
              attempts = 8
              while attempts > 0:
                  try:
                      data = api(url, raw=True)
                      break
                  except HTTPError as e:
                      if e.code == 404:
                          attempts -= 1
                          time.sleep(5)
                          continue
                      raise
              else:
                  print(f"skip: logs not yet available for run {rid} ({name})")
                  continue

              with zipfile.ZipFile(io.BytesIO(data)) as zf:
                  dest = root / f'{rn:08d}_{name}'
                  dest.mkdir(parents=True, exist_ok=True)
                  zf.extractall(dest)

          # Refresh "latest" by copying (no symlinks for portability)
          latest = root.parent / 'latest'
          if latest.exists():
              shutil.rmtree(latest)
          shutil.copytree(root, latest)
          PY

      - name: Commit and push logs
        # We already skip forks at the job level; push from any actor with write token
        shell: bash
        run: |
          set -Eeuo pipefail
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          # Force add in case .gitignore matches a broad *logs* rule
          git add -f ci-logs
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ci(logs): persist workflow logs for $HEAD_SHA [skip ci]"
            git pull --rebase -X ours origin "$HEAD_BRANCH" || true
            git push origin HEAD:"$HEAD_BRANCH"
          fi

